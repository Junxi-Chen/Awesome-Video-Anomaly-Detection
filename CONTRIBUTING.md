# Contributing to Awesome Video Anomaly Detection

Thank you for your interest in contributing to the Awesome-VAD repository üòÑ!  
We welcome pull requests to nominate high-quality research papers, datasets, benchmarks, and related resources in the field of video anomaly detection (VAD).

---

## üìå Contribution Guidelines

You are encouraged to nominate VAD-related papers or resources by submitting a pull request. To ensure the quality and relevance of the listed content, please follow the guidelines below.

### ‚úÖ Recommended Criteria for Paper Inclusion

We recommend nominating papers that meet **at least one** of the following criteria:

1. Published in top-tier conferences or journals (e.g., CVPR, ICCV, NeurIPS, ICLR, TPAMI, etc.);
2. Accompanied by **official or practical open-sourced code**; 
3. Of high research quality and representative of current trends in VAD.

---

## üìÑ How to Nominate a Paper

To nominate a paper, please complete the following steps:

### Step 1: Add the Paper to the Relevant Section

Format your entry as follows:

```markdown
1. [ShortName] **Full Paper Title** <a id='ShortName'></a>&nbsp;&nbsp;&nbsp;![New](https://img.shields.io/badge/New‚≠ê-417FFA)  
Badges  
Publication Venue [[paper](link)] [[code (optional)](link)] [[supp (optional)](link)] [[project (optional)](link)] [[annotation (optional)](link)] [[dataset (optional)](link)] [[OpenReview (optional)](link)]
```

üìå **Example:**

```markdown
1. [VANE-Bench] **VANE-Bench: Video Anomaly Evaluation Benchmark for Conversational LMMs** <a id='VANE-Bench'></a>&nbsp;&nbsp;&nbsp;![New](https://img.shields.io/badge/New‚≠ê-417FFA)\
![LLM](https://img.shields.io/badge/LLM-FFA500) ![benchmark](https://img.shields.io/badge/benchmark-548389) \
NAACL '25 [[paper](https://arxiv.org/pdf/2406.10326)][[code](https://github.com/rohit901/VANE-Bench)][[dataset](https://huggingface.co/datasets/rohit901/VANE-Bench)][[project](https://hananshafi.github.io/vane-benchmark/)]
```

### Optional Badges

Feel free to add the appropriate badges to highlight the paper's properties:

- ![LLM](https://img.shields.io/badge/LLM-FFA500)
- ![benchmark](https://img.shields.io/badge/benchmark-548389)
- ![I3D](https://img.shields.io/badge/I3D-35BF5C)
- ![with-Audio](https://img.shields.io/badge/with--Audio-00B2FF)
- ![CLIP-V](https://img.shields.io/badge/CLIP--V-6d4aff)
- ![CLIP-T](https://img.shields.io/badge/CLIP--T-C3B9FA)
- ![Hiera-L](https://img.shields.io/badge/Hiera--L-25D366)

---

### Step 2: Update the "Recent Updates" Section

To help track changes and new entries, please add the paper to the **Recent Updates** section.

---

### Step 3 (Optional): Update Benchmark or Dataset Tables

If the nominated paper introduces a new dataset or reports benchmark results, please consider updating the relevant benchmark and/or dataset tables accordingly.

---

## üôåüèª Thank You

We deeply appreciate your contributions to this community-driven project.  
If you have any questions or suggestions, feel free to open an issue or reach out via pull request comments.

Stay Awesome!
